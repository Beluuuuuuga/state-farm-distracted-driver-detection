{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "piano-preparation",
   "metadata": {},
   "source": [
    "## ライブラリインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "perfect-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Activation\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0, ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "instrumental-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_randvalue(value):\n",
    "    # Set a seed value\n",
    "    seed_value= value \n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    random.seed(seed_value)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed_value)\n",
    "    # 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "seed_value = 42\n",
    "set_randvalue(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-squad",
   "metadata": {},
   "source": [
    "## CSVロード & 半教師データ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "commercial-undergraduate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "      <td>0.020099</td>\n",
       "      <td>7.584666e-03</td>\n",
       "      <td>0.013422</td>\n",
       "      <td>0.005908</td>\n",
       "      <td>2.738102e-03</td>\n",
       "      <td>0.869602</td>\n",
       "      <td>2.999901e-03</td>\n",
       "      <td>0.008679</td>\n",
       "      <td>0.020682</td>\n",
       "      <td>0.048285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>3.774269e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>7.940220e-07</td>\n",
       "      <td>0.999396</td>\n",
       "      <td>8.523394e-08</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "      <td>0.482515</td>\n",
       "      <td>1.307274e-02</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>4.297219e-03</td>\n",
       "      <td>0.028058</td>\n",
       "      <td>1.605076e-03</td>\n",
       "      <td>0.015099</td>\n",
       "      <td>0.097214</td>\n",
       "      <td>0.340344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           img        c0            c1        c2        c3            c4  \\\n",
       "0    img_1.jpg  0.020099  7.584666e-03  0.013422  0.005908  2.738102e-03   \n",
       "1   img_10.jpg  0.000110  3.774269e-07  0.000001  0.000003  7.940220e-07   \n",
       "2  img_100.jpg  0.482515  1.307274e-02  0.001370  0.016425  4.297219e-03   \n",
       "\n",
       "         c5            c6        c7        c8        c9  \n",
       "0  0.869602  2.999901e-03  0.008679  0.020682  0.048285  \n",
       "1  0.999396  8.523394e-08  0.000191  0.000217  0.000080  \n",
       "2  0.028058  1.605076e-03  0.015099  0.097214  0.340344  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train001でアンサンブルし作成したcsv\n",
    "ensemble_df = pd.read_csv(\"../data/output/Train005_ensemble_sub.csv\")\n",
    "ensemble_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "latest-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_values = ensemble_df.values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "elementary-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_max_values = np.max(ensemble_values, axis=1)\n",
    "ensemble_max_indexes = np.argmax(ensemble_values, axis=1)\n",
    "ensemble_df[\"max_pred\"] = ensemble_max_values\n",
    "ensemble_df[\"label\"] = ensemble_max_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "addressed-understanding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "      <th>max_pred</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "      <td>0.020099</td>\n",
       "      <td>7.584666e-03</td>\n",
       "      <td>0.013422</td>\n",
       "      <td>0.005908</td>\n",
       "      <td>2.738102e-03</td>\n",
       "      <td>0.869602</td>\n",
       "      <td>2.999901e-03</td>\n",
       "      <td>0.008679</td>\n",
       "      <td>0.020682</td>\n",
       "      <td>0.048285</td>\n",
       "      <td>0.869602</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>3.774269e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>7.940220e-07</td>\n",
       "      <td>0.999396</td>\n",
       "      <td>8.523394e-08</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.999396</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "      <td>0.482515</td>\n",
       "      <td>1.307274e-02</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>4.297219e-03</td>\n",
       "      <td>0.028058</td>\n",
       "      <td>1.605076e-03</td>\n",
       "      <td>0.015099</td>\n",
       "      <td>0.097214</td>\n",
       "      <td>0.340344</td>\n",
       "      <td>0.482515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           img        c0            c1        c2        c3            c4  \\\n",
       "0    img_1.jpg  0.020099  7.584666e-03  0.013422  0.005908  2.738102e-03   \n",
       "1   img_10.jpg  0.000110  3.774269e-07  0.000001  0.000003  7.940220e-07   \n",
       "2  img_100.jpg  0.482515  1.307274e-02  0.001370  0.016425  4.297219e-03   \n",
       "\n",
       "         c5            c6        c7        c8        c9  max_pred  label  \n",
       "0  0.869602  2.999901e-03  0.008679  0.020682  0.048285  0.869602      5  \n",
       "1  0.999396  8.523394e-08  0.000191  0.000217  0.000080  0.999396      5  \n",
       "2  0.028058  1.605076e-03  0.015099  0.097214  0.340344  0.482515      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "returning-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 信頼値90%より値が大きい行を取得\n",
    "ensemble_df_over_thresh = ensemble_df[ensemble_df.max_pred > 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "changing-orleans",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "確率が95％より大きな行数 41870\n"
     ]
    }
   ],
   "source": [
    "print(\"確率が95％より大きな行数\",len(ensemble_df_over_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dependent-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_df = ensemble_df_over_thresh[[\"img\",\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "coated-africa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-7a62c462fd57>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ensemble_train_df[\"image\"] = ensemble_train_df[\"img\"]\n"
     ]
    }
   ],
   "source": [
    "ensemble_train_df[\"image\"] = ensemble_train_df[\"img\"]\n",
    "ensemble_train_df = ensemble_train_df.drop([\"img\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ranging-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 半教師あり学習用にDataFrame作成\n",
    "train_df = pd.read_csv(\"../data/input/csvs/train.csv\")\n",
    "# train_df[\"img\"] = train_df[\"image\"]\n",
    "merge_df = pd.concat([train_df, ensemble_train_df])\n",
    "merge_df = merge_df.reset_index()\n",
    "merge_df[\"label\"] = merge_df[\"label\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "recreational-reality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64294"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習データ数\n",
    "len(merge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "actual-leader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>img_100026.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>img_10003.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>img_100050.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>img_100074.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>img_10012.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64289</th>\n",
       "      <td>79717</td>\n",
       "      <td>img_9999.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64290</th>\n",
       "      <td>79719</td>\n",
       "      <td>img_99991.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64291</th>\n",
       "      <td>79720</td>\n",
       "      <td>img_99993.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64292</th>\n",
       "      <td>79722</td>\n",
       "      <td>img_99995.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64293</th>\n",
       "      <td>79724</td>\n",
       "      <td>img_99998.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64294 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index           image label\n",
       "0          0  img_100026.jpg     0\n",
       "1          1   img_10003.jpg     0\n",
       "2          2  img_100050.jpg     0\n",
       "3          3  img_100074.jpg     0\n",
       "4          4   img_10012.jpg     0\n",
       "...      ...             ...   ...\n",
       "64289  79717    img_9999.jpg     3\n",
       "64290  79719   img_99991.jpg     2\n",
       "64291  79720   img_99993.jpg     7\n",
       "64292  79722   img_99995.jpg     3\n",
       "64293  79724   img_99998.jpg     6\n",
       "\n",
       "[64294 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bronze-fence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9162\n",
       "3    9073\n",
       "4    8339\n",
       "5    8290\n",
       "2    7811\n",
       "6    6074\n",
       "7    5379\n",
       "0    3995\n",
       "8    3759\n",
       "9    2412\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ラベルごとの数\n",
    "merge_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-tension",
   "metadata": {},
   "source": [
    "## モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abandoned-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNetB0のモデルを作成\n",
    "def create_model(weight_flg=False):\n",
    "    weight = None\n",
    "    if weight_flg:\n",
    "        weight = \"../model/efficientnetb0_notop.h5\" # ImageNetで学習されたモデルをロード\n",
    "    # include_top=False; 全結合層なし\n",
    "#     base_model = EfficientNetB0(weights=weight, include_top=False, pooling='avg', input_shape=(224,224,3))\n",
    "    base_model = ResNet50(weights=\"imagenet\", include_top=False, pooling='avg', input_shape=(224,224,3))\n",
    "    x = Dense(512, activation='relu')(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "    model = Model(base_model.input, output)\n",
    "    \n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-routine",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "superb-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "epochs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "starting-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator作成\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20, # rotation range\n",
    "    width_shift_range=30/img_size, # 30 pixel\n",
    "    height_shift_range=30/img_size, # 30 pixel\n",
    "    zoom_range=0.2\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "massive-judge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51435 validated image filenames belonging to 10 classes.\n",
      "Found 12859 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/250\n",
      "1607/1607 [==============================] - 876s 545ms/step - loss: 0.5934 - accuracy: 0.8003 - val_loss: 0.7100 - val_accuracy: 0.8190\n",
      "Epoch 2/250\n",
      "1607/1607 [==============================] - 479s 298ms/step - loss: 0.1565 - accuracy: 0.9590 - val_loss: 0.2940 - val_accuracy: 0.9171\n",
      "Epoch 3/250\n",
      "1607/1607 [==============================] - 479s 298ms/step - loss: 0.1115 - accuracy: 0.9706 - val_loss: 0.1812 - val_accuracy: 0.9558\n",
      "Epoch 4/250\n",
      "1607/1607 [==============================] - 478s 298ms/step - loss: 0.0994 - accuracy: 0.9746 - val_loss: 2.1071 - val_accuracy: 0.6328\n",
      "Epoch 5/250\n",
      "1607/1607 [==============================] - 477s 297ms/step - loss: 0.0875 - accuracy: 0.9773 - val_loss: 0.4412 - val_accuracy: 0.8737\n",
      "Epoch 6/250\n",
      "1607/1607 [==============================] - 476s 296ms/step - loss: 0.0721 - accuracy: 0.9820 - val_loss: 0.1903 - val_accuracy: 0.9592\n",
      "Epoch 00006: early stopping\n",
      "Found 51435 validated image filenames belonging to 10 classes.\n",
      "Found 12859 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/250\n",
      "1607/1607 [==============================] - 480s 298ms/step - loss: 0.4436 - accuracy: 0.8606 - val_loss: 0.9310 - val_accuracy: 0.8617\n",
      "Epoch 2/250\n",
      "1607/1607 [==============================] - 478s 298ms/step - loss: 0.1436 - accuracy: 0.9620 - val_loss: 0.1578 - val_accuracy: 0.9621\n",
      "Epoch 3/250\n",
      "1607/1607 [==============================] - 478s 298ms/step - loss: 0.1209 - accuracy: 0.9700 - val_loss: 0.3551 - val_accuracy: 0.9019\n",
      "Epoch 4/250\n",
      "1607/1607 [==============================] - 478s 298ms/step - loss: 0.0969 - accuracy: 0.9756 - val_loss: 0.1266 - val_accuracy: 0.9681\n",
      "Epoch 5/250\n",
      "1607/1607 [==============================] - 477s 297ms/step - loss: 0.0887 - accuracy: 0.9772 - val_loss: 2.1620 - val_accuracy: 0.7318\n",
      "Epoch 6/250\n",
      "1607/1607 [==============================] - 478s 297ms/step - loss: 0.0880 - accuracy: 0.9786 - val_loss: 0.1019 - val_accuracy: 0.9702\n",
      "Epoch 7/250\n",
      "1607/1607 [==============================] - 478s 297ms/step - loss: 0.0662 - accuracy: 0.9827 - val_loss: 0.1143 - val_accuracy: 0.9739\n",
      "Epoch 8/250\n",
      "1607/1607 [==============================] - 477s 297ms/step - loss: 0.0676 - accuracy: 0.9833 - val_loss: 0.1090 - val_accuracy: 0.9795\n",
      "Epoch 9/250\n",
      "1607/1607 [==============================] - 480s 299ms/step - loss: 0.0545 - accuracy: 0.9858 - val_loss: 0.1510 - val_accuracy: 0.9589\n",
      "Epoch 00009: early stopping\n",
      "Found 51435 validated image filenames belonging to 10 classes.\n",
      "Found 12859 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/250\n",
      "1607/1607 [==============================] - 485s 302ms/step - loss: 0.8036 - accuracy: 0.7290 - val_loss: 0.5266 - val_accuracy: 0.8388\n",
      "Epoch 2/250\n",
      "1607/1607 [==============================] - 480s 298ms/step - loss: 0.1848 - accuracy: 0.9515 - val_loss: 0.3526 - val_accuracy: 0.9173\n",
      "Epoch 3/250\n",
      "1607/1607 [==============================] - 479s 298ms/step - loss: 0.1400 - accuracy: 0.9640 - val_loss: 0.1682 - val_accuracy: 0.9496\n",
      "Epoch 4/250\n",
      "1607/1607 [==============================] - 479s 298ms/step - loss: 0.1129 - accuracy: 0.9715 - val_loss: 0.0946 - val_accuracy: 0.9753\n",
      "Epoch 5/250\n",
      "1607/1607 [==============================] - 479s 298ms/step - loss: 0.0949 - accuracy: 0.9762 - val_loss: 0.0847 - val_accuracy: 0.9746\n",
      "Epoch 6/250\n",
      "1607/1607 [==============================] - 479s 298ms/step - loss: 0.0968 - accuracy: 0.9761 - val_loss: 0.0963 - val_accuracy: 0.9692\n",
      "Epoch 7/250\n",
      "1607/1607 [==============================] - 478s 297ms/step - loss: 0.0757 - accuracy: 0.9795 - val_loss: 0.1355 - val_accuracy: 0.9560\n",
      "Epoch 8/250\n",
      "1607/1607 [==============================] - 478s 297ms/step - loss: 0.0791 - accuracy: 0.9799 - val_loss: 1.7269 - val_accuracy: 0.6621\n",
      "Epoch 00008: early stopping\n",
      "Found 51435 validated image filenames belonging to 10 classes.\n",
      "Found 12859 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/250\n",
      "1607/1607 [==============================] - 484s 301ms/step - loss: 1.0189 - accuracy: 0.6370 - val_loss: 0.7240 - val_accuracy: 0.8058\n",
      "Epoch 2/250\n",
      "1607/1607 [==============================] - 486s 303ms/step - loss: 0.2150 - accuracy: 0.9376 - val_loss: 2.3739 - val_accuracy: 0.6523\n",
      "Epoch 3/250\n",
      "1607/1607 [==============================] - 489s 304ms/step - loss: 0.1520 - accuracy: 0.9594 - val_loss: 0.0433 - val_accuracy: 0.9878\n",
      "Epoch 4/250\n",
      "1607/1607 [==============================] - 482s 300ms/step - loss: 0.1175 - accuracy: 0.9684 - val_loss: 0.0600 - val_accuracy: 0.9818\n",
      "Epoch 5/250\n",
      "1607/1607 [==============================] - 482s 300ms/step - loss: 0.1123 - accuracy: 0.9707 - val_loss: 0.1154 - val_accuracy: 0.9679\n",
      "Epoch 6/250\n",
      "1607/1607 [==============================] - 483s 300ms/step - loss: 0.0930 - accuracy: 0.9754 - val_loss: 0.0234 - val_accuracy: 0.9928\n",
      "Epoch 7/250\n",
      "1607/1607 [==============================] - 481s 299ms/step - loss: 0.0822 - accuracy: 0.9779 - val_loss: 0.0586 - val_accuracy: 0.9864\n",
      "Epoch 8/250\n",
      "1607/1607 [==============================] - 481s 300ms/step - loss: 0.0718 - accuracy: 0.9814 - val_loss: 0.0240 - val_accuracy: 0.9913\n",
      "Epoch 9/250\n",
      "1607/1607 [==============================] - 483s 301ms/step - loss: 0.0736 - accuracy: 0.9811 - val_loss: 0.0241 - val_accuracy: 0.9942\n",
      "Epoch 00009: early stopping\n",
      "Found 51436 validated image filenames belonging to 10 classes.\n",
      "Found 12858 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/250\n",
      "1607/1607 [==============================] - 484s 301ms/step - loss: 0.5147 - accuracy: 0.8377 - val_loss: 0.1029 - val_accuracy: 0.9722\n",
      "Epoch 2/250\n",
      "1607/1607 [==============================] - 481s 299ms/step - loss: 0.1600 - accuracy: 0.9577 - val_loss: 0.0148 - val_accuracy: 0.9962\n",
      "Epoch 3/250\n",
      "1607/1607 [==============================] - 480s 299ms/step - loss: 0.1240 - accuracy: 0.9681 - val_loss: 0.1918 - val_accuracy: 0.9506\n",
      "Epoch 4/250\n",
      "1607/1607 [==============================] - 483s 300ms/step - loss: 0.1089 - accuracy: 0.9725 - val_loss: 0.2960 - val_accuracy: 0.9311\n",
      "Epoch 5/250\n",
      "1607/1607 [==============================] - 481s 299ms/step - loss: 0.1036 - accuracy: 0.9731 - val_loss: 0.0160 - val_accuracy: 0.9953\n",
      "Epoch 00005: early stopping\n",
      "Wall time: 5h 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 学習と評価データでのラベルの分布数を一定に保ち学習\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "splitter = skf.split(merge_df[\"image\"],merge_df[\"label\"])\n",
    "for i, (train_ids, valid_ids) in enumerate(splitter, 1):\n",
    "    # データ生成\n",
    "    train, valid = merge_df.iloc[train_ids], merge_df.iloc[valid_ids]\n",
    "    train_datagenerator = train_datagen.flow_from_dataframe(\n",
    "        train,\n",
    "        directory='../data/input/imgs/train/semi-supervised_imgs/',\n",
    "        x_col='image',\n",
    "        y_col='label',\n",
    "        target_size=(img_size, img_size),\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        seed=seed_value\n",
    "    )\n",
    "\n",
    "    valid_datagenerator = valid_datagen.flow_from_dataframe(\n",
    "        valid,\n",
    "        directory='../data/input/imgs/train/semi-supervised_imgs/',\n",
    "        x_col='image',\n",
    "        y_col='label',\n",
    "        target_size=(img_size, img_size),\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        seed=seed_value\n",
    "    )\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    # 早期終了\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    \n",
    "    # 早期終了するのでval_lossが小さいモデルを保存\n",
    "    model_path = '../model/' +  'Train006_' + \"fold\" + str(i) + \"_best_model.h5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "                    filepath=model_path,\n",
    "                    monitor='val_loss',\n",
    "                    save_best_only=True,\n",
    "                    period=1)\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_datagenerator,\n",
    "        steps_per_epoch=int(len(train)//batch_size),\n",
    "        epochs=epochs,\n",
    "        validation_data=valid_datagenerator,\n",
    "        validation_steps=int(len(valid)//batch_size),\n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-prison",
   "metadata": {},
   "source": [
    "## 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "outer-saturday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv('../data/input/csvs/sample_submission.csv')\n",
    "columns = submit.columns.values\n",
    "labels = submit.columns[1:].values\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    submit,\n",
    "    directory='../data/input/imgs/test/',\n",
    "    x_col='img',\n",
    "    y_col='c0', # ダミー変数\n",
    "    target_size=(img_size, img_size),\n",
    "    class_mode=None,\n",
    "    batch_size=1,\n",
    "    verbose=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "def inference(fold_num):\n",
    "    model = create_model()\n",
    "    weight_path = '../model/Train006_fold' + str(fold_num) + '_best_model.h5'\n",
    "    output_path = '../data/output/Train006_fold' + str(fold_num) + '_sub.csv'\n",
    "    model.load_weights(weight_path)\n",
    "    \n",
    "    pred = model.predict(test_generator, verbose=1)\n",
    "    pred_df = pd.DataFrame(columns=columns)\n",
    "    pred_df['img'] = submit['img']\n",
    "    pred_df[labels] = pred\n",
    "    pred_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "functioning-source",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79726/79726 [==============================] - 409s 5ms/step\n",
      "79726/79726 [==============================] - 417s 5ms/step\n",
      "79726/79726 [==============================] - 415s 5ms/step\n",
      "79726/79726 [==============================] - 409s 5ms/step\n",
      "79726/79726 [==============================] - 409s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    inference(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-grant",
   "metadata": {},
   "source": [
    "### アンサンブル：単純平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "correct-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../data/input/csvs/sample_submission.csv')\n",
    "columns = submit.columns.values\n",
    "labels = submit.columns[1:].values\n",
    "\n",
    "ensemble = 0\n",
    "for i in range(1,6):\n",
    "    path = \"../data/output/Train006_fold\" + str(i) +\"_sub.csv\"\n",
    "    ensemble += pd.read_csv(path).values[:,1:] / 5 # fold数で割る\n",
    "\n",
    "ensemble_df = pd.DataFrame(columns=columns)\n",
    "ensemble_df['img'] = submit['img']\n",
    "ensemble_df[labels] = ensemble\n",
    "\n",
    "ensemble_df.to_csv(\"../data/output/Train006_ensemble_sub.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-sacramento",
   "metadata": {},
   "source": [
    "### Train002のアンサンブルとTrain006のアンサンブルのアンサンブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "funded-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../data/input/csvs/sample_submission.csv')\n",
    "columns = submit.columns.values\n",
    "labels = submit.columns[1:].values\n",
    "\n",
    "ensemble = 0\n",
    "# for i in range(1,6):\n",
    "path1 = \"../data/output/Train006_ensemble_sub.csv\"\n",
    "path2 = \"../data/output/Train002_ensemble_sub.csv\"\n",
    "ensemble += pd.read_csv(path1).values[:,1:] * 0.2\n",
    "ensemble += pd.read_csv(path2).values[:,1:] * 0.8\n",
    "\n",
    "ensemble_df = pd.DataFrame(columns=columns)\n",
    "ensemble_df['img'] = submit['img']\n",
    "ensemble_df[labels] = ensemble\n",
    "\n",
    "ensemble_df.to_csv(\"../data/output/Train002_and_Train006_ensemble_sub.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-group",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
