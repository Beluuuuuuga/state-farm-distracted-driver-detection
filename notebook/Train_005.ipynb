{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "harmful-complexity",
   "metadata": {},
   "source": [
    "## ライブラリインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wrapped-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Activation\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0, EfficientNetB1, ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sophisticated-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_randvalue(value):\n",
    "    # Set a seed value\n",
    "    seed_value= value \n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    random.seed(seed_value)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed_value)\n",
    "    # 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "seed_value = 42\n",
    "set_randvalue(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-difference",
   "metadata": {},
   "source": [
    "## CSVロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "considerable-flashing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_100026.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10003.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100050.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image label\n",
       "0  img_100026.jpg     0\n",
       "1   img_10003.jpg     0\n",
       "2  img_100050.jpg     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train.csvが元のラベルごとにディレクトリに保存されていたデータから作成したcsv\n",
    "df = pd.read_csv(\"../data/input/csvs/train.csv\")\n",
    "df[\"label\"] = df[\"label\"].astype(str)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-upset",
   "metadata": {},
   "source": [
    "## モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "daily-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNetB0のモデルを作成\n",
    "def create_model(weight_flg=False):\n",
    "    weight = None\n",
    "    if weight_flg:\n",
    "        weight = \"../model/efficientnetb0_notop.h5\" # ImageNetで学習されたモデルをロード\n",
    "    # include_top=False; 全結合層なし\n",
    "#     base_model = EfficientNetB0(weights=weight, include_top=False, pooling='avg', input_shape=(224,224,3))\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(224,224,3))\n",
    "    x = Dense(512, activation='relu')(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    +\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "    model = Model(base_model.input, output)\n",
    "    \n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-prophet",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dynamic-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "epochs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "international-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator作成\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20, # rotation range\n",
    "    width_shift_range=30/img_size, # 30 pixel\n",
    "    height_shift_range=30/img_size, # 30 pixel\n",
    "    zoom_range=0.2\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "collaborative-receiver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17939 validated image filenames belonging to 10 classes.\n",
      "Found 4485 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/250\n",
      "560/560 [==============================] - 171s 305ms/step - loss: 1.9423 - accuracy: 0.2552 - val_loss: 2.4916 - val_accuracy: 0.0908\n",
      "Epoch 2/250\n",
      "560/560 [==============================] - 170s 304ms/step - loss: 0.7239 - accuracy: 0.7514 - val_loss: 3.4304 - val_accuracy: 0.4993\n",
      "Epoch 3/250\n",
      "560/560 [==============================] - 171s 305ms/step - loss: 0.3717 - accuracy: 0.8886 - val_loss: 0.5407 - val_accuracy: 0.8471\n",
      "Epoch 4/250\n",
      "560/560 [==============================] - 170s 304ms/step - loss: 0.2701 - accuracy: 0.9206 - val_loss: 0.3063 - val_accuracy: 0.9190\n",
      "Epoch 5/250\n",
      "560/560 [==============================] - 170s 304ms/step - loss: 0.2409 - accuracy: 0.9327 - val_loss: 0.3020 - val_accuracy: 0.9067\n",
      "Epoch 6/250\n",
      "560/560 [==============================] - 170s 303ms/step - loss: 0.1920 - accuracy: 0.9443 - val_loss: 0.8735 - val_accuracy: 0.7844\n",
      "Epoch 7/250\n",
      "560/560 [==============================] - 170s 303ms/step - loss: 0.1711 - accuracy: 0.9523 - val_loss: 0.6462 - val_accuracy: 0.8288\n",
      "Epoch 8/250\n",
      "560/560 [==============================] - 170s 304ms/step - loss: 0.1508 - accuracy: 0.9577 - val_loss: 0.1869 - val_accuracy: 0.9429\n",
      "Epoch 9/250\n",
      "560/560 [==============================] - 170s 303ms/step - loss: 0.1764 - accuracy: 0.9512 - val_loss: 0.2456 - val_accuracy: 0.9415\n",
      "Epoch 10/250\n",
      "560/560 [==============================] - 169s 303ms/step - loss: 0.1281 - accuracy: 0.9644 - val_loss: 0.6999 - val_accuracy: 0.8480\n",
      "Epoch 11/250\n",
      "560/560 [==============================] - 170s 304ms/step - loss: 0.1222 - accuracy: 0.9654 - val_loss: 0.1785 - val_accuracy: 0.9536\n",
      "Epoch 12/250\n",
      "560/560 [==============================] - 170s 304ms/step - loss: 0.1167 - accuracy: 0.9693 - val_loss: 0.1670 - val_accuracy: 0.9571\n",
      "Epoch 13/250\n",
      "560/560 [==============================] - 169s 302ms/step - loss: 0.1042 - accuracy: 0.9725 - val_loss: 0.2106 - val_accuracy: 0.9489\n",
      "Epoch 14/250\n",
      "560/560 [==============================] - 170s 304ms/step - loss: 0.1037 - accuracy: 0.9715 - val_loss: 0.1083 - val_accuracy: 0.9723\n",
      "Epoch 15/250\n",
      "560/560 [==============================] - 169s 302ms/step - loss: 0.0998 - accuracy: 0.9737 - val_loss: 0.1374 - val_accuracy: 0.9638\n",
      "Epoch 16/250\n",
      "560/560 [==============================] - 169s 302ms/step - loss: 0.1235 - accuracy: 0.9691 - val_loss: 0.1389 - val_accuracy: 0.9594\n",
      "Epoch 17/250\n",
      "560/560 [==============================] - 170s 303ms/step - loss: 0.0844 - accuracy: 0.9772 - val_loss: 0.0801 - val_accuracy: 0.9777\n",
      "Epoch 18/250\n",
      "560/560 [==============================] - 169s 302ms/step - loss: 0.0694 - accuracy: 0.9806 - val_loss: 0.1351 - val_accuracy: 0.9705\n",
      "Epoch 19/250\n",
      "560/560 [==============================] - 261s 467ms/step - loss: 0.0715 - accuracy: 0.9807 - val_loss: 0.0950 - val_accuracy: 0.9761\n",
      "Epoch 20/250\n",
      "560/560 [==============================] - 202s 361ms/step - loss: 0.0567 - accuracy: 0.9852 - val_loss: 0.1790 - val_accuracy: 0.9547\n",
      "Epoch 00020: early stopping\n",
      "Found 17939 validated image filenames belonging to 10 classes.\n",
      "Found 4485 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/250\n",
      "560/560 [==============================] - 170s 304ms/step - loss: 1.4444 - accuracy: 0.4661 - val_loss: 2.6036 - val_accuracy: 0.0893\n",
      "Epoch 2/250\n",
      "560/560 [==============================] - 170s 304ms/step - loss: 0.5180 - accuracy: 0.8243 - val_loss: 0.5086 - val_accuracy: 0.8371\n",
      "Epoch 3/250\n",
      "560/560 [==============================] - 171s 305ms/step - loss: 0.3446 - accuracy: 0.8965 - val_loss: 0.4166 - val_accuracy: 0.8708\n",
      "Epoch 4/250\n",
      "560/560 [==============================] - 171s 305ms/step - loss: 0.2693 - accuracy: 0.9242 - val_loss: 0.3464 - val_accuracy: 0.9054\n",
      "Epoch 5/250\n",
      "560/560 [==============================] - 170s 304ms/step - loss: 0.2131 - accuracy: 0.9400 - val_loss: 0.5350 - val_accuracy: 0.8641\n",
      "Epoch 6/250\n",
      "560/560 [==============================] - 171s 305ms/step - loss: 0.1863 - accuracy: 0.9505 - val_loss: 0.1813 - val_accuracy: 0.9460\n",
      "Epoch 7/250\n",
      "560/560 [==============================] - 170s 304ms/step - loss: 0.1836 - accuracy: 0.9485 - val_loss: 0.1411 - val_accuracy: 0.9560\n",
      "Epoch 8/250\n",
      "560/560 [==============================] - 169s 302ms/step - loss: 0.1480 - accuracy: 0.9580 - val_loss: 0.1797 - val_accuracy: 0.9429\n",
      "Epoch 9/250\n",
      "560/560 [==============================] - 170s 303ms/step - loss: 0.1394 - accuracy: 0.9601 - val_loss: 0.4197 - val_accuracy: 0.8859\n",
      "Epoch 10/250\n",
      "560/560 [==============================] - 170s 303ms/step - loss: 0.1324 - accuracy: 0.9636 - val_loss: 0.1967 - val_accuracy: 0.9438\n",
      "Epoch 00010: early stopping\n",
      "Found 17939 validated image filenames belonging to 10 classes.\n",
      "Found 4485 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/250\n",
      "560/560 [==============================] - 170s 304ms/step - loss: 1.7588 - accuracy: 0.3074 - val_loss: 3.8000 - val_accuracy: 0.0920\n",
      "Epoch 2/250\n",
      "560/560 [==============================] - 169s 302ms/step - loss: 0.7281 - accuracy: 0.7464 - val_loss: 0.8228 - val_accuracy: 0.7411\n",
      "Epoch 3/250\n",
      "560/560 [==============================] - 169s 302ms/step - loss: 0.4124 - accuracy: 0.8661 - val_loss: 0.6161 - val_accuracy: 0.8210\n",
      "Epoch 4/250\n",
      "560/560 [==============================] - 169s 302ms/step - loss: 0.2986 - accuracy: 0.9150 - val_loss: 0.2581 - val_accuracy: 0.9290\n",
      "Epoch 5/250\n",
      "560/560 [==============================] - 169s 301ms/step - loss: 0.2299 - accuracy: 0.9347 - val_loss: 0.7690 - val_accuracy: 0.8388\n",
      "Epoch 6/250\n",
      "560/560 [==============================] - 169s 301ms/step - loss: 0.2056 - accuracy: 0.9405 - val_loss: 0.3219 - val_accuracy: 0.9199\n",
      "Epoch 7/250\n",
      "560/560 [==============================] - 169s 301ms/step - loss: 0.1721 - accuracy: 0.9506 - val_loss: 0.3429 - val_accuracy: 0.9009\n",
      "Epoch 00007: early stopping\n",
      "Found 17939 validated image filenames belonging to 10 classes.\n",
      "Found 4485 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/250\n",
      "560/560 [==============================] - 172s 307ms/step - loss: 1.1405 - accuracy: 0.6053 - val_loss: 2.6371 - val_accuracy: 0.0895\n",
      "Epoch 2/250\n",
      "560/560 [==============================] - 171s 305ms/step - loss: 0.3769 - accuracy: 0.8893 - val_loss: 0.2914 - val_accuracy: 0.9107\n",
      "Epoch 3/250\n",
      "560/560 [==============================] - 170s 304ms/step - loss: 0.2602 - accuracy: 0.9275 - val_loss: 0.5325 - val_accuracy: 0.8406\n",
      "Epoch 4/250\n",
      "560/560 [==============================] - 170s 303ms/step - loss: 0.2345 - accuracy: 0.9356 - val_loss: 0.3519 - val_accuracy: 0.9051\n",
      "Epoch 5/250\n",
      "560/560 [==============================] - 171s 304ms/step - loss: 0.1950 - accuracy: 0.9444 - val_loss: 0.2823 - val_accuracy: 0.9136\n",
      "Epoch 6/250\n",
      "560/560 [==============================] - 171s 305ms/step - loss: 0.1664 - accuracy: 0.9536 - val_loss: 0.1091 - val_accuracy: 0.9719\n",
      "Epoch 7/250\n",
      "560/560 [==============================] - 170s 304ms/step - loss: 0.1585 - accuracy: 0.9562 - val_loss: 0.1197 - val_accuracy: 0.9712\n",
      "Epoch 8/250\n",
      "560/560 [==============================] - 172s 307ms/step - loss: 0.1358 - accuracy: 0.9634 - val_loss: 0.4131 - val_accuracy: 0.9069\n",
      "Epoch 9/250\n",
      "560/560 [==============================] - 171s 304ms/step - loss: 0.1252 - accuracy: 0.9669 - val_loss: 0.4420 - val_accuracy: 0.8781\n",
      "Epoch 00009: early stopping\n",
      "Found 17940 validated image filenames belonging to 10 classes.\n",
      "Found 4484 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/250\n",
      "560/560 [==============================] - 171s 306ms/step - loss: 1.4149 - accuracy: 0.4773 - val_loss: 6.3111 - val_accuracy: 0.0893\n",
      "Epoch 2/250\n",
      "560/560 [==============================] - 170s 303ms/step - loss: 0.5107 - accuracy: 0.8312 - val_loss: 0.6670 - val_accuracy: 0.8009\n",
      "Epoch 3/250\n",
      "560/560 [==============================] - 169s 303ms/step - loss: 0.3299 - accuracy: 0.9040 - val_loss: 0.5391 - val_accuracy: 0.8551\n",
      "Epoch 4/250\n",
      "560/560 [==============================] - 169s 302ms/step - loss: 0.2451 - accuracy: 0.9330 - val_loss: 0.6039 - val_accuracy: 0.8286\n",
      "Epoch 5/250\n",
      "560/560 [==============================] - 169s 301ms/step - loss: 0.2121 - accuracy: 0.9385 - val_loss: 1.1029 - val_accuracy: 0.7725\n",
      "Epoch 6/250\n",
      "560/560 [==============================] - 170s 303ms/step - loss: 0.1926 - accuracy: 0.9462 - val_loss: 0.2487 - val_accuracy: 0.9196\n",
      "Epoch 7/250\n",
      "560/560 [==============================] - 170s 303ms/step - loss: 0.1592 - accuracy: 0.9562 - val_loss: 0.2075 - val_accuracy: 0.9393\n",
      "Epoch 8/250\n",
      "560/560 [==============================] - 169s 302ms/step - loss: 0.1453 - accuracy: 0.9621 - val_loss: 0.3355 - val_accuracy: 0.8984\n",
      "Epoch 9/250\n",
      "560/560 [==============================] - 169s 302ms/step - loss: 0.1427 - accuracy: 0.9610 - val_loss: 0.2407 - val_accuracy: 0.9250\n",
      "Epoch 10/250\n",
      "560/560 [==============================] - 170s 303ms/step - loss: 0.1227 - accuracy: 0.9683 - val_loss: 0.1549 - val_accuracy: 0.9643\n",
      "Epoch 11/250\n",
      "560/560 [==============================] - 169s 301ms/step - loss: 0.1258 - accuracy: 0.9681 - val_loss: 1.1065 - val_accuracy: 0.7710\n",
      "Epoch 12/250\n",
      "560/560 [==============================] - 169s 301ms/step - loss: 0.1019 - accuracy: 0.9725 - val_loss: 0.2621 - val_accuracy: 0.9478\n",
      "Epoch 13/250\n",
      "560/560 [==============================] - 169s 302ms/step - loss: 0.1141 - accuracy: 0.9691 - val_loss: 0.2356 - val_accuracy: 0.9328\n",
      "Epoch 00013: early stopping\n",
      "Wall time: 2h 50min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 学習と評価データでのラベルの分布数を一定に保ち学習\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle=True, random_state=0)\n",
    "splitter = skf.split(df[\"image\"],df[\"label\"])\n",
    "for i, (train_ids, valid_ids) in enumerate(splitter, 1):\n",
    "#     if i == 1: continue\n",
    "    # データ生成\n",
    "    train, valid = df.iloc[train_ids], df.iloc[valid_ids]\n",
    "    train_datagenerator = train_datagen.flow_from_dataframe(\n",
    "        train,\n",
    "        directory='../data/input/imgs/train/imgs/',\n",
    "        x_col='image',\n",
    "        y_col='label',\n",
    "        target_size=(img_size, img_size),\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        seed=seed_value\n",
    "    )\n",
    "\n",
    "    valid_datagenerator = valid_datagen.flow_from_dataframe(\n",
    "        valid,\n",
    "        directory='../data/input/imgs/train/imgs/',\n",
    "        x_col='image',\n",
    "        y_col='label',\n",
    "        target_size=(img_size, img_size),\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        seed=seed_value\n",
    "    )\n",
    "    \n",
    "    model = create_model(weight_flg=True)\n",
    "    \n",
    "    # 早期終了\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    \n",
    "    # 早期終了するのでval_lossが小さいモデルを保存\n",
    "    model_path = '../model/' +  'Train005_' + \"fold\" + str(i) + \"_best_model.h5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "                    filepath=model_path,\n",
    "                    monitor='val_loss',\n",
    "                    save_best_only=True,\n",
    "                    period=1)\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_datagenerator,\n",
    "        steps_per_epoch=int(len(train)//batch_size),\n",
    "        epochs=epochs,\n",
    "        validation_data=valid_datagenerator,\n",
    "        validation_steps=int(len(valid)//batch_size),\n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-narrow",
   "metadata": {},
   "source": [
    "## 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "synthetic-suicide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 validated image filenames.\n",
      "79726/79726 [==============================] - 758s 10ms/step\n",
      "79726/79726 [==============================] - 419s 5ms/step\n",
      "79726/79726 [==============================] - 428s 5ms/step\n",
      "79726/79726 [==============================] - 424s 5ms/step\n",
      "79726/79726 [==============================] - 420s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv('../data/input/csvs/sample_submission.csv')\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    submit,\n",
    "    directory='../data/input/imgs/test/',\n",
    "    x_col='img',\n",
    "    y_col='c0', # ダミー変数\n",
    "    target_size=(img_size, img_size),\n",
    "    class_mode=None,\n",
    "    batch_size=1,\n",
    "    verbose=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "columns = submit.columns.values\n",
    "labels = submit.columns[1:].values\n",
    "\n",
    "def inference(fold_num):\n",
    "    model = create_model()\n",
    "    weight_path = '../model/Train005_fold' + str(fold_num) + '_best_model.h5'\n",
    "    output_path = '../data/output/Train005_fold' + str(fold_num) + '_sub.csv'\n",
    "    model.load_weights(weight_path)\n",
    "    \n",
    "    pred = model.predict(test_generator, verbose=1)\n",
    "    pred_df = pd.DataFrame(columns=columns)\n",
    "    pred_df['img'] = submit['img']\n",
    "    pred_df[labels] = pred\n",
    "    pred_df.to_csv(output_path, index=False)\n",
    "    \n",
    "for i in range(1,6):\n",
    "    inference(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-struggle",
   "metadata": {},
   "source": [
    "#### アンサンブル：単純平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "inner-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../data/input/csvs/sample_submission.csv')\n",
    "columns = submit.columns.values\n",
    "labels = submit.columns[1:].values\n",
    "\n",
    "ensemble = 0\n",
    "for i in range(1,6):\n",
    "    path = \"../data/output/Train005_fold\" + str(i) +\"_sub.csv\"\n",
    "    ensemble += pd.read_csv(path).values[:,1:] / 5 # fold数で割る\n",
    "\n",
    "ensemble_df = pd.DataFrame(columns=columns)\n",
    "ensemble_df['img'] = submit['img']\n",
    "ensemble_df[labels] = ensemble\n",
    "\n",
    "ensemble_df.to_csv(\"../data/output/Train005_ensemble_sub.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-multiple",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
