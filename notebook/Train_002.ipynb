{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "strong-ministry",
   "metadata": {},
   "source": [
    "## ライブラリインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "divided-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Activation\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "leading-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_randvalue(value):\n",
    "    # Set a seed value\n",
    "    seed_value= value \n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    random.seed(seed_value)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed_value)\n",
    "    # 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "seed_value = 42\n",
    "set_randvalue(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-watson",
   "metadata": {},
   "source": [
    "## CSVロード & 半教師データ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accredited-registrar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.180500e-10</td>\n",
       "      <td>1.019599e-07</td>\n",
       "      <td>2.198193e-07</td>\n",
       "      <td>1.692227e-08</td>\n",
       "      <td>0.999800</td>\n",
       "      <td>1.977041e-08</td>\n",
       "      <td>3.659118e-07</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.039500e-10</td>\n",
       "      <td>1.336446e-08</td>\n",
       "      <td>2.174772e-07</td>\n",
       "      <td>2.943974e-09</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>3.690732e-09</td>\n",
       "      <td>1.368859e-07</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "      <td>0.627001</td>\n",
       "      <td>4.329754e-03</td>\n",
       "      <td>1.251251e-03</td>\n",
       "      <td>1.407811e-02</td>\n",
       "      <td>8.127563e-03</td>\n",
       "      <td>0.016387</td>\n",
       "      <td>2.568727e-03</td>\n",
       "      <td>1.114982e-02</td>\n",
       "      <td>0.096248</td>\n",
       "      <td>0.218859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           img        c0            c1            c2            c3  \\\n",
       "0    img_1.jpg  0.000005  2.180500e-10  1.019599e-07  2.198193e-07   \n",
       "1   img_10.jpg  0.000006  1.039500e-10  1.336446e-08  2.174772e-07   \n",
       "2  img_100.jpg  0.627001  4.329754e-03  1.251251e-03  1.407811e-02   \n",
       "\n",
       "             c4        c5            c6            c7        c8        c9  \n",
       "0  1.692227e-08  0.999800  1.977041e-08  3.659118e-07  0.000015  0.000179  \n",
       "1  2.943974e-09  0.999944  3.690732e-09  1.368859e-07  0.000005  0.000044  \n",
       "2  8.127563e-03  0.016387  2.568727e-03  1.114982e-02  0.096248  0.218859  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train001でアンサンブルし作成したcsv\n",
    "ensemble_df = pd.read_csv(\"../data/output/Train001_ensemble_sub.csv\")\n",
    "ensemble_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "meaning-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_values = ensemble_df.values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "communist-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_max_values = np.max(ensemble_values, axis=1)\n",
    "ensemble_max_indexes = np.argmax(ensemble_values, axis=1)\n",
    "ensemble_df[\"max_pred\"] = ensemble_max_values\n",
    "ensemble_df[\"label\"] = ensemble_max_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "celtic-infrared",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "      <th>max_pred</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.180500e-10</td>\n",
       "      <td>1.019599e-07</td>\n",
       "      <td>2.198193e-07</td>\n",
       "      <td>1.692227e-08</td>\n",
       "      <td>0.999800</td>\n",
       "      <td>1.977041e-08</td>\n",
       "      <td>3.659118e-07</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.039500e-10</td>\n",
       "      <td>1.336446e-08</td>\n",
       "      <td>2.174772e-07</td>\n",
       "      <td>2.943974e-09</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>3.690732e-09</td>\n",
       "      <td>1.368859e-07</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "      <td>0.627001</td>\n",
       "      <td>4.329754e-03</td>\n",
       "      <td>1.251251e-03</td>\n",
       "      <td>1.407811e-02</td>\n",
       "      <td>8.127563e-03</td>\n",
       "      <td>0.016387</td>\n",
       "      <td>2.568727e-03</td>\n",
       "      <td>1.114982e-02</td>\n",
       "      <td>0.096248</td>\n",
       "      <td>0.218859</td>\n",
       "      <td>0.627001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           img        c0            c1            c2            c3  \\\n",
       "0    img_1.jpg  0.000005  2.180500e-10  1.019599e-07  2.198193e-07   \n",
       "1   img_10.jpg  0.000006  1.039500e-10  1.336446e-08  2.174772e-07   \n",
       "2  img_100.jpg  0.627001  4.329754e-03  1.251251e-03  1.407811e-02   \n",
       "\n",
       "             c4        c5            c6            c7        c8        c9  \\\n",
       "0  1.692227e-08  0.999800  1.977041e-08  3.659118e-07  0.000015  0.000179   \n",
       "1  2.943974e-09  0.999944  3.690732e-09  1.368859e-07  0.000005  0.000044   \n",
       "2  8.127563e-03  0.016387  2.568727e-03  1.114982e-02  0.096248  0.218859   \n",
       "\n",
       "   max_pred  label  \n",
       "0    0.9998      5  \n",
       "1  0.999944      5  \n",
       "2  0.627001      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "funky-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 信頼値90%より値が大きい行を取得\n",
    "ensemble_df_over_thresh = ensemble_df[ensemble_df.max_pred > 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "criminal-excuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "確率が95％より大きな行数 41563\n"
     ]
    }
   ],
   "source": [
    "print(\"確率が95％より大きな行数\",len(ensemble_df_over_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "realistic-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_df = ensemble_df_over_thresh[[\"img\",\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ethical-discretion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-7a62c462fd57>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ensemble_train_df[\"image\"] = ensemble_train_df[\"img\"]\n"
     ]
    }
   ],
   "source": [
    "ensemble_train_df[\"image\"] = ensemble_train_df[\"img\"]\n",
    "ensemble_train_df = ensemble_train_df.drop([\"img\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "clean-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 半教師あり学習用にDataFrame作成\n",
    "train_df = pd.read_csv(\"../data/input/csvs/train.csv\")\n",
    "# train_df[\"img\"] = train_df[\"image\"]\n",
    "merge_df = pd.concat([train_df, ensemble_train_df])\n",
    "merge_df = merge_df.reset_index()\n",
    "merge_df[\"label\"] = merge_df[\"label\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "million-adolescent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63987"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習データ数\n",
    "len(merge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "norwegian-suspension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>img_100026.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>img_10003.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>img_100050.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>img_100074.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>img_10012.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63982</th>\n",
       "      <td>79720</td>\n",
       "      <td>img_99993.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63983</th>\n",
       "      <td>79722</td>\n",
       "      <td>img_99995.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63984</th>\n",
       "      <td>79723</td>\n",
       "      <td>img_99996.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63985</th>\n",
       "      <td>79724</td>\n",
       "      <td>img_99998.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63986</th>\n",
       "      <td>79725</td>\n",
       "      <td>img_99999.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63987 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index           image label\n",
       "0          0  img_100026.jpg     0\n",
       "1          1   img_10003.jpg     0\n",
       "2          2  img_100050.jpg     0\n",
       "3          3  img_100074.jpg     0\n",
       "4          4   img_10012.jpg     0\n",
       "...      ...             ...   ...\n",
       "63982  79720   img_99993.jpg     7\n",
       "63983  79722   img_99995.jpg     3\n",
       "63984  79723   img_99996.jpg     4\n",
       "63985  79724   img_99998.jpg     6\n",
       "63986  79725   img_99999.jpg     5\n",
       "\n",
       "[63987 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "casual-console",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    9327\n",
       "3    9183\n",
       "4    8227\n",
       "2    7789\n",
       "1    6393\n",
       "7    6138\n",
       "6    5953\n",
       "8    4343\n",
       "0    3428\n",
       "9    3206\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ラベルごとの数\n",
    "merge_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-dressing",
   "metadata": {},
   "source": [
    "## モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "biological-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNetB0のモデルを作成\n",
    "def create_model(weight_flg=False):\n",
    "    weight = None\n",
    "    if weight_flg:\n",
    "        weight = \"../model/efficientnetb0_notop.h5\" # ImageNetで学習されたモデルをロード\n",
    "    # include_top=False; 全結合層なし\n",
    "    base_model = EfficientNetB0(weights=weight, include_top=False, pooling='avg', input_shape=(224,224,3))\n",
    "    x = Dense(512, activation='relu')(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "    model = Model(base_model.input, output)\n",
    "    \n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-journey",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "exempt-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "img_size = 224\n",
    "batch_size = 16\n",
    "epochs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prompt-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator作成\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20, # rotation range\n",
    "    width_shift_range=30/img_size, # 30 pixel\n",
    "    height_shift_range=30/img_size, # 30 pixel\n",
    "    zoom_range=0.2\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "removed-warner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51189 validated image filenames belonging to 10 classes.\n",
      "Found 12798 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/250\n",
      "3199/3199 [==============================] - 866s 271ms/step - loss: 1.0508 - accuracy: 0.6278 - val_loss: 0.4350 - val_accuracy: 0.8613\n",
      "Epoch 2/250\n",
      "3199/3199 [==============================] - 664s 208ms/step - loss: 0.2880 - accuracy: 0.9094 - val_loss: 0.2610 - val_accuracy: 0.9250\n",
      "Epoch 3/250\n",
      "3199/3199 [==============================] - 488s 153ms/step - loss: 0.1913 - accuracy: 0.9470 - val_loss: 0.2581 - val_accuracy: 0.9329\n",
      "Epoch 4/250\n",
      "3199/3199 [==============================] - 487s 152ms/step - loss: 0.1591 - accuracy: 0.9566 - val_loss: 0.2139 - val_accuracy: 0.9573\n",
      "Epoch 5/250\n",
      "3199/3199 [==============================] - 487s 152ms/step - loss: 0.1314 - accuracy: 0.9654 - val_loss: 0.1643 - val_accuracy: 0.9571\n",
      "Epoch 6/250\n",
      "3199/3199 [==============================] - 483s 151ms/step - loss: 0.1181 - accuracy: 0.9691 - val_loss: 0.1934 - val_accuracy: 0.9661\n",
      "Epoch 7/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 0.1069 - accuracy: 0.9725 - val_loss: 0.2600 - val_accuracy: 0.9468\n",
      "Epoch 8/250\n",
      "3199/3199 [==============================] - 717s 224ms/step - loss: 0.0949 - accuracy: 0.9751 - val_loss: 0.1590 - val_accuracy: 0.9625\n",
      "Epoch 9/250\n",
      "3199/3199 [==============================] - 620s 194ms/step - loss: 0.0893 - accuracy: 0.9779 - val_loss: 0.1553 - val_accuracy: 0.9642\n",
      "Epoch 10/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 0.0941 - accuracy: 0.9774 - val_loss: 0.1015 - val_accuracy: 0.9775\n",
      "Epoch 11/250\n",
      "3199/3199 [==============================] - 482s 151ms/step - loss: 0.0749 - accuracy: 0.9810 - val_loss: 0.1268 - val_accuracy: 0.9754\n",
      "Epoch 12/250\n",
      "3199/3199 [==============================] - 481s 150ms/step - loss: 0.0765 - accuracy: 0.9814 - val_loss: 0.1172 - val_accuracy: 0.9793\n",
      "Epoch 13/250\n",
      "3199/3199 [==============================] - 482s 151ms/step - loss: 0.0750 - accuracy: 0.9811 - val_loss: 0.1409 - val_accuracy: 0.9701\n",
      "Epoch 00013: early stopping\n",
      "Found 51189 validated image filenames belonging to 10 classes.\n",
      "Found 12798 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/250\n",
      "3199/3199 [==============================] - 483s 151ms/step - loss: 1.1996 - accuracy: 0.5679 - val_loss: 0.4112 - val_accuracy: 0.8752\n",
      "Epoch 2/250\n",
      "3199/3199 [==============================] - 481s 150ms/step - loss: 0.3138 - accuracy: 0.9054 - val_loss: 0.2113 - val_accuracy: 0.9444\n",
      "Epoch 3/250\n",
      "3199/3199 [==============================] - 481s 150ms/step - loss: 0.2043 - accuracy: 0.9435 - val_loss: 0.2645 - val_accuracy: 0.9410\n",
      "Epoch 4/250\n",
      "3199/3199 [==============================] - 485s 152ms/step - loss: 0.1727 - accuracy: 0.9553 - val_loss: 0.1883 - val_accuracy: 0.9465\n",
      "Epoch 5/250\n",
      "3199/3199 [==============================] - 485s 152ms/step - loss: 0.1416 - accuracy: 0.9638 - val_loss: 0.1303 - val_accuracy: 0.9694\n",
      "Epoch 6/250\n",
      "3199/3199 [==============================] - 485s 152ms/step - loss: 0.1221 - accuracy: 0.9683 - val_loss: 0.1391 - val_accuracy: 0.9697\n",
      "Epoch 7/250\n",
      "3199/3199 [==============================] - 485s 151ms/step - loss: 0.1132 - accuracy: 0.9718 - val_loss: 0.1150 - val_accuracy: 0.9674\n",
      "Epoch 8/250\n",
      "3199/3199 [==============================] - 485s 151ms/step - loss: 0.1035 - accuracy: 0.9744 - val_loss: 0.1655 - val_accuracy: 0.9674\n",
      "Epoch 9/250\n",
      "3199/3199 [==============================] - 483s 151ms/step - loss: 0.0973 - accuracy: 0.9754 - val_loss: 0.0943 - val_accuracy: 0.9760\n",
      "Epoch 10/250\n",
      "3199/3199 [==============================] - 481s 150ms/step - loss: 0.0884 - accuracy: 0.9780 - val_loss: 0.0665 - val_accuracy: 0.9812\n",
      "Epoch 11/250\n",
      "3199/3199 [==============================] - 480s 150ms/step - loss: 0.0827 - accuracy: 0.9796 - val_loss: 0.1042 - val_accuracy: 0.9736\n",
      "Epoch 12/250\n",
      "3199/3199 [==============================] - 481s 150ms/step - loss: 0.0826 - accuracy: 0.9794 - val_loss: 0.0890 - val_accuracy: 0.9788\n",
      "Epoch 13/250\n",
      "3199/3199 [==============================] - 481s 150ms/step - loss: 0.0823 - accuracy: 0.9812 - val_loss: 0.0741 - val_accuracy: 0.9808\n",
      "Epoch 00013: early stopping\n",
      "Found 51190 validated image filenames belonging to 10 classes.\n",
      "Found 12797 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/250\n",
      "3199/3199 [==============================] - 487s 152ms/step - loss: 1.2897 - accuracy: 0.5352 - val_loss: 0.3223 - val_accuracy: 0.8746\n",
      "Epoch 2/250\n",
      "3199/3199 [==============================] - 485s 152ms/step - loss: 0.3356 - accuracy: 0.8996 - val_loss: 0.1317 - val_accuracy: 0.9608\n",
      "Epoch 3/250\n",
      "3199/3199 [==============================] - 485s 152ms/step - loss: 0.2255 - accuracy: 0.9390 - val_loss: 0.1165 - val_accuracy: 0.9689\n",
      "Epoch 4/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 0.1718 - accuracy: 0.9546 - val_loss: 0.0583 - val_accuracy: 0.9829\n",
      "Epoch 5/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 0.1513 - accuracy: 0.9605 - val_loss: 0.1205 - val_accuracy: 0.9695\n",
      "Epoch 6/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 0.1338 - accuracy: 0.9662 - val_loss: 0.0703 - val_accuracy: 0.9818\n",
      "Epoch 7/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 0.1192 - accuracy: 0.9698 - val_loss: 0.0490 - val_accuracy: 0.9866\n",
      "Epoch 8/250\n",
      "3199/3199 [==============================] - 485s 151ms/step - loss: 0.1115 - accuracy: 0.9720 - val_loss: 0.0556 - val_accuracy: 0.9841\n",
      "Epoch 9/250\n",
      "3199/3199 [==============================] - 485s 152ms/step - loss: 0.1011 - accuracy: 0.9754 - val_loss: 0.0390 - val_accuracy: 0.9894\n",
      "Epoch 10/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 0.0930 - accuracy: 0.9760 - val_loss: 0.0621 - val_accuracy: 0.9841\n",
      "Epoch 11/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 0.0932 - accuracy: 0.9775 - val_loss: 0.0550 - val_accuracy: 0.9833\n",
      "Epoch 12/250\n",
      "3199/3199 [==============================] - 485s 152ms/step - loss: 0.0896 - accuracy: 0.9786 - val_loss: 0.0286 - val_accuracy: 0.9917\n",
      "Epoch 13/250\n",
      "3199/3199 [==============================] - 485s 152ms/step - loss: 0.0804 - accuracy: 0.9804 - val_loss: 0.0295 - val_accuracy: 0.9933\n",
      "Epoch 14/250\n",
      "3199/3199 [==============================] - 485s 151ms/step - loss: 0.0814 - accuracy: 0.9797 - val_loss: 0.0368 - val_accuracy: 0.9890\n",
      "Epoch 15/250\n",
      "3199/3199 [==============================] - 485s 152ms/step - loss: 0.0756 - accuracy: 0.9815 - val_loss: 0.0379 - val_accuracy: 0.9901\n",
      "Epoch 00015: early stopping\n",
      "Found 51190 validated image filenames belonging to 10 classes.\n",
      "Found 12797 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/250\n",
      "3199/3199 [==============================] - 487s 152ms/step - loss: 1.5127 - accuracy: 0.4534 - val_loss: 0.2857 - val_accuracy: 0.8786\n",
      "Epoch 2/250\n",
      "3199/3199 [==============================] - 485s 152ms/step - loss: 0.4137 - accuracy: 0.8677 - val_loss: 0.0981 - val_accuracy: 0.9712\n",
      "Epoch 3/250\n",
      "3199/3199 [==============================] - 485s 152ms/step - loss: 0.2600 - accuracy: 0.9230 - val_loss: 0.0724 - val_accuracy: 0.9768\n",
      "Epoch 4/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 0.1939 - accuracy: 0.9464 - val_loss: 0.0342 - val_accuracy: 0.9893\n",
      "Epoch 5/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 0.1652 - accuracy: 0.9563 - val_loss: 0.0237 - val_accuracy: 0.9929\n",
      "Epoch 6/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 0.1452 - accuracy: 0.9639 - val_loss: 0.0191 - val_accuracy: 0.9957\n",
      "Epoch 7/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 0.1303 - accuracy: 0.9671 - val_loss: 0.0112 - val_accuracy: 0.9975\n",
      "Epoch 8/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 0.1147 - accuracy: 0.9711 - val_loss: 0.0206 - val_accuracy: 0.9962\n",
      "Epoch 9/250\n",
      "3199/3199 [==============================] - 485s 151ms/step - loss: 0.1119 - accuracy: 0.9720 - val_loss: 0.0148 - val_accuracy: 0.9966\n",
      "Epoch 10/250\n",
      "3199/3199 [==============================] - 485s 152ms/step - loss: 0.1032 - accuracy: 0.9743 - val_loss: 0.0107 - val_accuracy: 0.9971\n",
      "Epoch 11/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 0.0956 - accuracy: 0.9763 - val_loss: 0.0248 - val_accuracy: 0.9918\n",
      "Epoch 12/250\n",
      "3199/3199 [==============================] - 485s 152ms/step - loss: 0.0976 - accuracy: 0.9760 - val_loss: 0.0153 - val_accuracy: 0.9959\n",
      "Epoch 13/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 0.0908 - accuracy: 0.9775 - val_loss: 0.0121 - val_accuracy: 0.9964\n",
      "Epoch 00013: early stopping\n",
      "Found 51190 validated image filenames belonging to 10 classes.\n",
      "Found 12797 validated image filenames belonging to 10 classes.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 1.4772 - accuracy: 0.4579 - val_loss: 0.3835 - val_accuracy: 0.8373\n",
      "Epoch 2/250\n",
      "3199/3199 [==============================] - 483s 151ms/step - loss: 0.4307 - accuracy: 0.8551 - val_loss: 0.2269 - val_accuracy: 0.9122\n",
      "Epoch 3/250\n",
      "3199/3199 [==============================] - 483s 151ms/step - loss: 0.2765 - accuracy: 0.9133 - val_loss: 0.0495 - val_accuracy: 0.9841\n",
      "Epoch 4/250\n",
      "3199/3199 [==============================] - 485s 152ms/step - loss: 0.2074 - accuracy: 0.9412 - val_loss: 0.0478 - val_accuracy: 0.9883\n",
      "Epoch 5/250\n",
      "3199/3199 [==============================] - 483s 151ms/step - loss: 0.1688 - accuracy: 0.9540 - val_loss: 0.0083 - val_accuracy: 0.9980\n",
      "Epoch 6/250\n",
      "3199/3199 [==============================] - 483s 151ms/step - loss: 0.1441 - accuracy: 0.9614 - val_loss: 0.0123 - val_accuracy: 0.9970\n",
      "Epoch 7/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 0.1277 - accuracy: 0.9657 - val_loss: 0.0173 - val_accuracy: 0.9938\n",
      "Epoch 8/250\n",
      "3199/3199 [==============================] - 484s 151ms/step - loss: 0.1189 - accuracy: 0.9688 - val_loss: 0.0430 - val_accuracy: 0.9883\n",
      "Epoch 00008: early stopping\n",
      "Wall time: 8h 36min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 学習と評価データでのラベルの分布数を一定に保ち学習\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "splitter = skf.split(merge_df[\"image\"],merge_df[\"label\"])\n",
    "for i, (train_ids, valid_ids) in enumerate(splitter, 1):\n",
    "    # データ生成\n",
    "    train, valid = merge_df.iloc[train_ids], merge_df.iloc[valid_ids]\n",
    "    train_datagenerator = train_datagen.flow_from_dataframe(\n",
    "        train,\n",
    "        directory='../data/input/imgs/train/semi-supervised_imgs/',\n",
    "        x_col='image',\n",
    "        y_col='label',\n",
    "        target_size=(img_size, img_size),\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        seed=seed_value\n",
    "    )\n",
    "\n",
    "    valid_datagenerator = valid_datagen.flow_from_dataframe(\n",
    "        valid,\n",
    "        directory='../data/input/imgs/train/semi-supervised_imgs/',\n",
    "        x_col='image',\n",
    "        y_col='label',\n",
    "        target_size=(img_size, img_size),\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        seed=seed_value\n",
    "    )\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    # 早期終了\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    \n",
    "    # 早期終了するのでval_lossが小さいモデルを保存\n",
    "    model_path = '../model/' +  'Train002_' + \"fold\" + str(i) + \"_best_model.h5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "                    filepath=model_path,\n",
    "                    monitor='val_loss',\n",
    "                    save_best_only=True,\n",
    "                    period=1)\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_datagenerator,\n",
    "        steps_per_epoch=int(len(train)//batch_size),\n",
    "        epochs=epochs,\n",
    "        validation_data=valid_datagenerator,\n",
    "        validation_steps=int(len(valid)//batch_size),\n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-uruguay",
   "metadata": {},
   "source": [
    "## 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "instructional-advancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv('../data/input/csvs/sample_submission.csv')\n",
    "columns = submit.columns.values\n",
    "labels = submit.columns[1:].values\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    submit,\n",
    "    directory='../data/input/imgs/test/',\n",
    "    x_col='img',\n",
    "    y_col='c0', # ダミー変数\n",
    "    target_size=(img_size, img_size),\n",
    "    class_mode=None,\n",
    "    batch_size=1,\n",
    "    verbose=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "def inference(fold_num):\n",
    "    model = create_model()\n",
    "    weight_path = '../model/Train002_fold' + str(fold_num) + '_best_model.h5'\n",
    "    output_path = '../data/output/Train002_fold' + str(fold_num) + '_sub.csv'\n",
    "    model.load_weights(weight_path)\n",
    "    \n",
    "    pred = model.predict(test_generator, verbose=1)\n",
    "    pred_df = pd.DataFrame(columns=columns)\n",
    "    pred_df['img'] = submit['img']\n",
    "    pred_df[labels] = pred\n",
    "    pred_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sorted-dallas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79726/79726 [==============================] - 755s 9ms/step\n",
      "79726/79726 [==============================] - 469s 6ms/step\n",
      "79726/79726 [==============================] - 460s 6ms/step\n",
      "79726/79726 [==============================] - 458s 6ms/step\n",
      "79726/79726 [==============================] - 463s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    inference(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-stick",
   "metadata": {},
   "source": [
    "### アンサンブル：単純平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "otherwise-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../data/input/csvs/sample_submission.csv')\n",
    "columns = submit.columns.values\n",
    "labels = submit.columns[1:].values\n",
    "\n",
    "ensemble = 0\n",
    "for i in range(1,6):\n",
    "    path = \"../data/output/Train002_fold\" + str(i) +\"_sub.csv\"\n",
    "    ensemble += pd.read_csv(path).values[:,1:] / 5 # fold数で割る\n",
    "\n",
    "ensemble_df = pd.DataFrame(columns=columns)\n",
    "ensemble_df['img'] = submit['img']\n",
    "ensemble_df[labels] = ensemble\n",
    "\n",
    "ensemble_df.to_csv(\"../data/output/Train002_ensemble_sub.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-farming",
   "metadata": {},
   "source": [
    "#### アンサンブル：加重平均\n",
    "\n",
    "fold数ごとのPublic scoreを元に加重平均  \n",
    "  \n",
    " fold: Public score  \n",
    " fold1: 0.35424  \n",
    " fold2: 0.44200  \n",
    " fold3: 0.32399  \n",
    " fold4: 0.40812  \n",
    " fold5: 0.55640  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "legislative-communications",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold1_weight = 0.25\n",
    "fold2_weight = 0.25\n",
    "fold3_weight = 0.25\n",
    "fold4_weight = 0.25\n",
    "fold5_weight = 0.125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "willing-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../data/input/csvs/sample_submission.csv')\n",
    "columns = submit.columns.values\n",
    "labels = submit.columns[1:].values\n",
    "\n",
    "weighted_ensemble = 0\n",
    "for i in range(1,6):\n",
    "    path = \"../data/output/Train002_fold\" + str(i) +\"_sub.csv\"\n",
    "    weight = 1\n",
    "    if i == 1: weight = fold1_weight\n",
    "    elif i == 2: weight = fold2_weight\n",
    "    elif i == 3: weight = fold3_weight\n",
    "    elif i == 4: weight = fold4_weight\n",
    "    elif i == 5: weight = fold5_weight\n",
    "        \n",
    "    weighted_ensemble += pd.read_csv(path).values[:,1:] * weight # foldの重みを掛ける\n",
    "\n",
    "ensemble_df = pd.DataFrame(columns=columns)\n",
    "ensemble_df['img'] = submit['img']\n",
    "ensemble_df[labels] = weighted_ensemble\n",
    "\n",
    "ensemble_df.to_csv(\"../data/output/Train002_weighted_ensemble_sub.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-stereo",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
